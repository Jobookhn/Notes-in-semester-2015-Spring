#并行计算模型与系统
##一、概述
并行计算出现得比多核编程早，在大型机上早已出现
###1.Flynn分类法
####SISD
* 传统的计算机
* 速度受处理器的处理速度决定
####SIMD
* Intel MMX  
处理多媒体数据
* CRAY向量机
* 同一时刻，各个处理器做的指令完全一致，但接受的数据不同
####MISD
* 只是理论模型，并没有实际应用  
可以做出来，但成本和MIMD也差不多
* 可用于容错处理
* 流水线架构机器
####MIMD
* 将多个可以同时处理的事情完全分开
* 多条数据同时进入，接受不同处理
* 按存储类型还可继续划分
#####共享存储
* 各个处理单元使用统一的存储
* 缺点：性能上存在瓶颈  
内存带宽是最大问题  
CPU的内存访问会存在冲突
#####分布存储
* 存储分布在不同的处理单元中
* 不同单元通过高速网络进行通讯  
IPC（Inter-Process Communication）
####SPMD与MPMD
MIMD可以被进一步划分

* SPMD  
限定不同处理器执行同一个程序
* MPMD  
不同处理器可以执行多个不同的程序
###2.Converging System Architectures
* 无共享体系结构
* 共享磁盘体系结构
* 共享存储体系结构

*注：实际的机器一定不会将缓存、寄存器共享，因为缓存都是针对特定处理器的*
##二、并行计算机模型
主要是理论模型，用于设计并行算法
###1.含义
来自程序员视角的抽象并行机，不同于冯诺依曼架构中的顺序执行
###2.模型的定义
通过语义属性和性能属性描述
####语义属性
* 同构性  
执行并行程序时，并行计算机中处理器的行为相似到何种程度  
该模型如何分类到Flynn标准中
* 同步性  
处理器执行指令的同步方式，同步有多严格
* 交互机制  
处理器的执行线索之间如何相互影响  
如何获知对方的数据
* 地址空间  
进程或线程可访问的地址空间
	* 单地址空间/多地址空间  
	多地址空间时，两个CPU的内存空间并不完全重合，同一地址可能对应不同的物理单元
	* 均匀存储器访问（UMA，Uniform Memory Access）/非均匀存储器访问（NUMA，Non-Uniform Memory Access）  
	访问一段存储器内容不同单元的速度相同或不同  
	虚存、远程存储等因素都可能造成此现象
* 存储器模型  
如何处理共享存储器的访问冲突
####性能属性
* 机器规模  
可以并行执行的计算单元数量，无量纲
* 时钟速率
* 工作负载  
程序运行完成需要的指令数量  
不同的指令类型执行时间不同，因此这里统一以浮点指令为衡量标准，单位为Mflops
* 顺序执行时间
* 并行执行时间
* 速度  
单位时间执行的工作量
* 加速比
* 效率  
单位核心上的加速比
* 利用率  
并行计算的速度与多台机器并行计算的速度和的比  
主要是硬件效率
* 启动时间
* 渐进带宽  
主要用于描述网络在长期传输（如一个大包）时能达到的稳定速率
###3.并行系统中的操作和开销
####并行系统中的操作类型
* 计算操作  
原有串行计算机中的所有操作类型
* 并行操作  
管理进程/线程的操作，包括创建/终止、分组和上下文切换
* 交互操作
####并行系统的开销
很多开销在原有的并行程序中并不存在

* 并行开销  
因进程/线程管理产生的开销
* 通信开销
* 同步开销
* 负载不平衡开销  
因各个计算单元的负载分配不平衡而产生的开销，不是由指令引起的  
如果负载的平均的，各计算单元都能满负荷运行，任务量大小的分别造成了执行时间的加长
###4.不可并行实例
####Ackerman函数
* 一般递归问题
* 求值到后期相当巨大
* 必须要求将返回值表之前的返回值全部计算出来
####更一般性的实例
* 加密算法  
设计者特意如此，一旦加密算法可并行，密码的破解会相当容易
* 无理数逼近  
通过迭代法进行，没有之前的结果不可进行后一次迭代
* 工作流、控制流
###5.PRAM模型
并行随机访问模型
####简单介绍
* 若干个处理器，一个共享空间，一个公共时钟  
各个处理器执行的指令的开始时刻一致  
*需要与主频一致区别开来*
* 均匀存储访问
* MIMD
* 细粒度
* 严格同步
* 零开销
* 共享变量
* 机器规模可以任意大
* 每个周期内，每个处理器只执行一条指令  
可能是空指令（`NOP`），则此周期闲置
* 所有处理器隐式同步  
同步开销、通信开销、并行开销都为零  
唯一的开销就是负载不平衡开销
	* 在时钟控制下自然同步，没有同步指令，也就没有同步开销
	* 共享存储器后不需要向其它处理器通信要求数据，直接从存储器取即可，没有通信开销
	* PRAM中没有启动进程、线程的问题，没有并行开销
* 一个周期中可以以一条指令完成读存储器、算术操作、写存储器三个操作
####语义属性
* 同构性  
n=1时，对应SISD，n>1时对应MIMD
* 同步性  
指令级别的同步
* 交互机制  
各进程通过共享变量（或存储器）进行交互
* 地址空间  
单地址空间+UMA
* 存储器模型  
EREW  
排斥（Exclusive）读、排斥写
####PRAM的应用
> ######问题：向量内积
> n个处理器的EREW PRAM上，对两个N维向量A、B求内积s，当N很大时（N>>n），求加速比。（假设乘法和加法各占一个时钟周期）

乘法一共N次，加法一共(N-1)次，串行计算需要的周期数为(2N-1)  
并行计算时，乘法可以完全均匀分配，加法除了最后几部分，前面的都可以平均分配  
一共需要(2N-1-(n-1))/n+logn个周期  
分子的n-1是剩下的可以平均分配的加法操作  
于是加速比显然
####优点
简单，多数的理论并行算法都使用PRAM或其变异进行描述，也被广泛用来分析并行算法复杂度
####缺点
对零通信开销和指令级同步的不现实假设
###6.APRAM模型
* 克服PRAM模型的缺点，保留其简单性
* 比PRAM模型更接近实际的并行计算机
* 计算由一系列用同步路障分开的全局phase组成  
因此也称Phase PRAM
####特点
* 每个处理器有其本地存储器、局部时钟和局部程序
* 处理器间的通信经过共享的全局存储器
* 没有全局式中，各处理器异步执行指令
* 时间依赖关系需要明确地加入同步路障
* 一条指令在非确定但有限的时间内完成
####指令类型
* 全局读
* 全局写
* 局部操作
* 同步
###7.BSP模型（Bulk Synchronizaiton Parallel）
* MIMD
* 超步：计算、通信、路障
* 可变颗粒度
* 松同步
* 非零开销
* 消息传递
####超步
BSP模型中的计算由一系列同步路障分开的超步组成

* 超步由计算操作、通信操作、同步操作组成  
假定局部操作可在一定时间内完成，每一超步中，一个处理器至多发送或接受h条消息
	* 一个超步中有且只有一次同步
* 执行一个超步的最大时间：W+gh+l  
W：每个超步内的最大运行时间，g：发送每条消息的开销，l：路障同步开销
####BSP的应用
> 仍然是向量内积

* 在树以外，进行乘法与加法操作时不需要进行同步，可以直接分配
* 每层需要一次同步，至少一次通信获取另一个操作数

并行执行时间为(2N-1-(n-1))/n+logn*(g+l+1)
##三、内存访问模型
主要考虑机器的存储分布
###1.多级存储体系结构
如果只需要计算机工作起来，只要有一种存储器即可，根本不需要这样的体系结构  
存储器容量的发展可以跟上性能的发展，但性能不行

* 解决内存墙的性能瓶颈问题
* 节点内部的cache是L2，内部更小的cache是L1
* 随着层次提高，每bit的成本增加
####cache的映射策略
* 全关联映射
* 直接映射
* n-路组关联映射
###2.并行计算机访存模型
####UMA模型
* 物理存储器被所有节点共享
* 所有节点访问任意存储单元的时间相同
* 发生访存竞争时，仲裁策略对每个节点平等对待
* 各节点的CPU可带有局部私有高速缓存
* 外围I/O设备也可以共享，且每个节点有平等的访问权利
####NUMA模型
* 物理存储器被所有节点共享，任意节点可以直接访问任意内存模块
* 节点访问内存模块的速度不同  
访问本地存储模块的速度一般是访问其它节点内存模块的3倍以上  
*3倍以下的速度差异，一般也近似认为是均匀存储访问*
* 发生访存竞争时，仲裁策略对节点是不等价的  
存在优先级的差异
* 各节点的CPU可带有局部私有高速缓存
* 外围I/O设备也可以共享，但对各节点是不等价的
####COMA模型（Cache-Only Memory Access）
COMA的本质是一种特殊的NUMA

* 各处理器节点中没有存储层次结构，全部高速缓存组成了全局地址空间
* 利用分布的高速缓存目录D进行远程高速缓存的访问
* COMA中的高速缓存容量一般都大于L2 Cache容量
* 使用COMA时，数据开始时可以任意分配，因为在运行时最终会被迁移到要用到它的地方  
使用数据时，放在哪个CPU的cache中都没有关系，因为最后都会缓存到自己的cache中来
####NORMA模型（No-Remote Memory Access）
* 所有存储器都是私有的
* 绝大多数NORMA都**不支持直接访问远程存储器**
* 在DSM中，NORMA就消失了
####CC-NUMA
保证缓存一致性的NUMA
#####缓存一致性
相同信息项在不同层次存储器中拷贝保持一致，如果某个存储块被修改，其它层次的缓存块就必须被更新
######单处理器下的缓存一致性策略
* 写直达法（write-through）  
每次向缓存写入时也同时写入内存，通常需要专用策略
* 写回法（write-back）  
在存储块从缓存中替换出来时，将其写入内存
######监听一致性协议
* 写无效协议  
在本地cache被修改后，使所有其它位置的数据拷贝失效  
在没有专用电路时，写无效协议的效率更高
* 写更新协议  
在本地cache被修改后，广播修改的数据，使得其它位置的数据拷贝得以及时更新

***CC-NUMA就这样使用了访问一致性***

* 大多数使用基于目录的高速缓存一致性协议  
目录保留着内存块的共享信息
* 保留SMP结构易于编程的优点，也改善常规SMP的可扩展性  
写程序不需要关心内存读/写的来源，一旦计算能力不够，可以通过增加节点的方式实现
* CC-NUMA实际上是一个分布共享存储的DSM多处理机系统  
这里的共享存储是软件层面的东西，通过系统封装来实现
#####优点
程序员无需明确地在节点上分配数据，系统的硬件和软件开始时自动地在各节点分配数据，在运行期间，高速缓存一致性硬件会自动地将数据迁移到需要用到它的地方
###3.内存访问模型分类
* MIMD
	* 多处理器（单地址空间共享存储器）
		* 中央存储器UMA
		* 分布存储器NUMA
	* NORMA
		* Cluster
		* MPP
##四、典型并行计算系统
考虑具体的机器，从整个架构全方位地研究
###1.SMP（Symmetric Multi-Processor）
*现行多核PC的架构即为SMP*

* 各个处理器一模一样
* 处理器在总线上的接口是对称的  
接到同一条总线上
* 所有内存都是共享内存
* 采用均匀存储访问
####优点
* 结构对称，使用单一操作系统
* 所有处理器通过个高速总线或交叉开关与共享存储器相连，具有单一的地址空间
* 通过读/写共享变量完成通信，快捷且编程比较容易
####缺点
* 存储器和I/O负载大，易成为系统的瓶颈，限制了系统中处理器的数量  
总线会成为整个SMP的瓶颈，CPU通常在32个以内，CPU和内存都不能无限制地增加  
内存由所有CPU共享，CPU越多，内存冲突的概率就越大；要解决这些冲突，要么加锁影响性能，要么放任导致错误
* 单点失效会导致整个系统的崩溃  
各处理器的设计是对称的，一旦处理器损坏，对称性就损坏了
* 一次成型，**扩展性差**  
不能随意增加和减少CPU数量
###2.PVP（Parallel Vector Processors）
* 对应于SIMD的结构
* 通过限制处理的指令提高处理器的吞吐量和性能
* GPU仍偏好使用此类VP处理器

*不重点考核*
###3.MPP（Massive Parallel Processor）
* 由上千台处理机组成
* 每个节点有自己的处理器与内存，通过**定制网络**将这些节点相连  
因而存储是分布式的
* 3T性能目标
	* Tflops计算能力
	* TB主存容量
	* TB/s的I/O带宽
* 解决“重大挑战性”问题
* 开发困难，价格高，市场有限
####特性
* 专门设计制造高速互联网络
* 节点内有一个或多个处理器、高速缓存、一个本地存储器和互连网络
* 每个处理器只能直接访问本地存储器，而不能直接访问其它处理器的存储器
* 程序由多个进程组成，进程间采用消息传递机制
* 使用专用硬件提升性能，技术复杂，成本高
###4.Cluster（或COW）
* 与MPP不同，直接使用商用网络与商用硬件  
成本远低于MPP
* 每个节点都是一个完整的计算机
* 各节点都有本地磁盘
* 节点与系统级网络的网络接口连接到I/O总线上（松耦合）  
而MPP的网络接口连接到存储总线上（紧耦合）
* 每个节点都有完整的操作系统  
甚至不同的节点操作系统可以不同
####特点
#####高性价比
* 硬件方面  
主要使用商用计算机硬件，造价低，配置灵活
* 软件方面  
大量使用开源软件系统
* 能够以更低的价格获得更高的峰值计算速度
#####良好的可扩展性
* 可以根据需要灵活调整集群系统的规模
#####易获得性，配置灵活
* 设计建造技术要求降低
* 可以用有限的资金获得高峰值速度
* 突破SMP和MPP的技术限制
* 可以根据实际情况挑选集群系统的各种组件
#####提供多用途的并行计算系统
* 科学计算、商业应用、互联网应用……