#并行编程基础
##一、综述
###1.什么是并行编程
	并行编程是对给定算法构造并行程序的活动。

*算法与体系结构之间的接口*
###2.现状：并行软件与串行软件
###3.编程模型
程序员在开发一个并行程序时所见到和使用的模型
####自然模型
一个特定并行计算机平台所提供的、用户可见的最底层的编程模型
####高层编程模型
在自然模型上加以实现
###4.并行编程进展
* 尽管大多数算法基于PRAM模型，但大多数经过修正后可以实用
* 并行算法已逐渐被用户所接受
* 自然模型集中趋向于单地址空间的共享变脸模型和多地址空间的消息传递模型  
SIMD模型已经淡出
* 高层并行编程模型集中趋向于数据并行、消息传递和共享变量  
还有隐式并行的编程模型
##二、并行编程模型
###1.并行编程环境
* 有给定的算法
* 编写程序
* 通过编译程序得到自然并行代码
* 要并有并行平台的支持

因此，可以以下方式提供并行接口：

* 提供并行库
* 提供新的并行语言
* 提供自动化的并行编译器
###2.显式并行与隐式并行
####显式并行
* 在源程序中有程序员使用专用语言构造、编译器命令或库函数对并行性加以显式说明
* 共享变量模型、消息传递模型、数据并行模型
####隐式并行
* 程序员不显式地说明并行性，而是让编译器或运行支持系统自动进行开发
* 12
###3.并行化方法
####环境支持
主要是对Fortran或C进行扩展
#####例程库
在串行语言中加入一组新的库函数，以支持并行化和交互操作  
如MPI库、POSIX PThread多线程库
#####新构造
扩展程序设计语言使其具有某些新构造，以支持并行化和交互
#####编译器命令/预处理
程序设计语言不变，但加入称为编译器命令的格式化注解

*Java是在虚拟机之上的高层次形式，目前存在一些并行机制，但并未统一，比如Hadoop*
####举例
#####串行代码
	for(i=0;i<N;i++)
		A[i]=b[i]*b[i+1];
	for(i=0;i<N;i++)
		C[i]=A[i]+A[i+1];
#####使用库例程的等效并行代码
	id=my_process_id();				//当前程序所在的核
	p=number_of_processes();
	for(i=id;i<N;i+=p)
		A[i]=b[i]*b[i+1];			//对核心1，执行i=1,5,9,13,...的计算操作
	barrier();						//路障同步，避免因任务负载不均匀产生可能的错误
	for(i=id;i<N;i+=p)
		c[i]=A[i]+A[i+1];
#####Fortran 90中使用数组操作的等效代码
	my_process_id(),number_of_processes(),and barrier()	//以上是一段声明
	A(0:N-1)=b(0:N-1)*b(1:N)							//在语句上做向量操作
	c=A(0:N-1)+A(1:N)
#####SGI Power C中使用pragma的等效代码
	#pragma parallel					//预编译指令仍然由编译器处理
	#pragma shared(A,b,c)				//通报各变量的共享情况
	#pragma local(i)
	{
		#pragma pfor iterate(i=0;N;1)	//要求编译器对此for循环实现并行分配
			for(i=0;i<N;i++)
				A[i]=b[i]*b[i+1];
		#pragma synchronize
		#pragma pfor iterate(i=0;N;1)
			for(i=0;i<N;i++)
				c[i]=A[i]+A[i+1];
	}
####总结
#####库例程
* 实例  
MPI、PVM、Cray Craft
* 优点  
易于实现，不需要新的编译器
* 缺点  
无编译器检查、分析和优化
#####新构造
* 实例  
Fortran 90、Cray Craft
* 优点  
允许编译器检查、分析和优化
* 缺点  
实现困难，需要新编译器，用户也需要学习新语言
#####命令
* 实例  
HPF、Cray Craft
* 优缺点  
介于库例程和新构造方法之间，在串行平台上不起作用
###4.显式并行编程模型
####数据并行
* 单控制流
* 松散同步
* 单地址空间
* 隐式交互
* 隐式或半显式的数据分配
* 以HPF和IPP为典型代表
* 可在SMP、DSM、MPP上移植
* 以进程级别的细粒度并行
* 学习入门偏易

*Fortran 90的并行方式基本可以看作是数据并行的代码*
####消息传递
* 多控制流
* 异步同步
* 多地址空间
* 显式交互
* 显式数据分配
* 以MPI和PVM为典型代表
* 可在所有主流并行计算机上移植
* 以进程级别的大粒度并行
* 学习入门较难
####共享变量
* 多控制流
* 异步同步
* 单地址空间
* 显式交互
* 隐式或半显式的数据分配
* 以OpenMP为典型代表
* 可在SMP、DDSM上移植
* 以**线程**级别的细粒度并行
* 学习入门容易
###4.其它并行编程模型
除命令式语言以外的方法

* 函数式编程
* 逻辑编程
* 通过机器学习进行计算
* 面向对象编程
##三、并行编程的策略和方法
###1.分解
将应用程序划分成多个独立的任务，并确定这些任务之间的相互依赖关系

*此问题在考虑需求本身时就应当涉及*
####分解方式
#####任务分解
从功能角度进行分解
#####数据分解
各部分拥有相同的功能，但这些功能使用的数据不同  
*可以有效地提高数据吞吐量*
#####数据流分解
分解数据的处理阶段
####任务分解与数据流分解
#####数据分解与两者的关系
显然
#####任务分解与两者的关系
以UML中的各种图为类比

* 任务分解对应活动图  
体现各个流程的变化
* 数据流分解对应数据流图  
数据流图和活动图可以完全不相关
####总结
#####任务分解
* 不同的程序行为采用不同的进程或线程实现
* 常用于GUI应用程序
#####数据分解
* 多个进程活线程对不同的数据块执行相同的操作
* 常用于音频、图像处理和科学计算应用程序
#####数据流分解
* 对数据处理阶段的不同操作进行分解
* 需要注意尽量消除启动和排空延迟
###2.并行编程面对的挑战和问题
* 同步  
两个或多个进程（线程）协调其行为的过程
* 通信  
线程（或进程）之间交互数据相关的带宽和延迟问题
* 负载平衡  
使线程活进程的工作量尽量平均分配
* 可扩展性  
在性能更强劲的系统上性能能否线性增长
###3.并行编程的模式
####设计模式
* 描述在特定上下文中解决重复问题的有效方法
* 遵循一定的格式，包括模式名、背景、面对的问题因素（即目标和限制）、解决方案
* 记录专家经验，供遇到类似问题的其他人员参考
####任务并行模式
#####问题
当问题被最好地分解为一个能够并发执行的任务集合时，如何高效地开发这种并行性
#####背景
* 设计直接基于任务
* 并行算法以一个并发任务集合为基础
* 识别任务及其相关性
#####面临问题
* 负载平衡
* 管理任务相关性
#####示例
* 医学成像PET  
对一系列的巨量图像进行处理  
可以做任务并行（按图像校正的不同处理过程分解），也可以做数据并行（按人体部位分块）
* 分子动力学  
将一个大分子分解为多个部分，成为数据分解  
将不同旋转方向的作用情况分别计算，成为任务分解
#####解决方案
* 任务  
两个标准
	* 任务的数目至少与处理单元的数目一样多
	* 与每个任务相关的计算量必须足够多
* 相关性  
顺序约束，和共享有关的相关性
* 调度  
静态调度/动态调度
* 程序结构  
循环结构/任务队列
* 常用术语  
易并行问题、复制数据或规约问题
#####分阶段并行
* 将程序分为若干个超步
* 每个超步包含计算阶段和交互阶段
* 又称为**松散并行模式**和**日程模式**
####分治
* 主过程将工作分给多个子过程，子过程的结果最终再合并给主过程
* 通常可以递归实现
* 存在小部分不可并行的部分
* 如果划分合理，各计算单元的负载就比较均衡
####几何分解
* 数据分解在设计阶段的称呼
* 将所要解决问题中使用的数据结构并行化
* 每个线程只负责一些数据块上的操作
####流水线
* 数据流分解在设计阶段的称呼
* 连续的数据流被放置进流水线
* 不同的处理步骤同时、重叠地处理不同的数据
###4.范例与分解方式
* 阶段并行->任务分解或数据分解
* 分治模式->任务分解或数据分解
* 几何分解模式->数据分解
* 流水线模式->数据流烦呢姐